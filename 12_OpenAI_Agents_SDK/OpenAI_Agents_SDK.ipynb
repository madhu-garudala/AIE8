{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=â€falseâ€ ><img src=\"https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\" id=\"heading\">OpenAI Agents SDK - AIM</h1>\n",
    "\n",
    "In this notebook, we'll go over some of the key features of the OpenAI Agents SDK - as explored through a notebook-ified version of their [Research Bot](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to run this cell if you're running this notebook locally. \n",
    "\n",
    "#!pip install -qU openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nest Async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "As may be expected, the primary thing we'll do in the Agents SDK is construct Agents!\n",
    "\n",
    "Agents are constructed with a few basic properties:\n",
    "\n",
    "- A prompt, which OpenAI is using the language \"instruction\" for, that determines the behaviour or goal of the Agent\n",
    "- A model, the \"brain\" of the Agent\n",
    "\n",
    "They also typically include an additional property: \n",
    "\n",
    "- Tool(s) that equip the Agent with things it can use to get stuff done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Planner Agent\n",
    "\n",
    "Let's start by creating our \"Planner Agent\" - which will come up with the initial set of search terms that should answer a query provided by the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent\n",
    "\n",
    "PLANNER_PROMPT = (\n",
    "    \"You are a helpful research assistant. Given a query, come up with a set of web searches to perform\" \n",
    "    \"to best answer the query. Output between 5 and 20 terms to query for.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the data models that our Planner Agent will use to structure its output. We'll create:\n",
    "\n",
    "1. `WebSearchItem` - A model for individual search items, containing the search query and reasoning\n",
    "2. `WebSearchPlan` - A container model that holds a list of search items\n",
    "\n",
    "These Pydantic models will help ensure our agent returns structured data that we can easily process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query.\"\n",
    "\n",
    "    query: str\n",
    "    \"The search term to use for the web search.\"\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"\"\"A list of web searches to perform to best answer the query.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Planner Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `PLANNER_PROMPT` and will output structured data in the form of our WebSearchPlan model. We're using the GPT-4o model for this agent to ensure high-quality search term generation.\n",
    "\n",
    "> NOTE: When we provide an `output_type` - the model will return a [structured response](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=PLANNER_PROMPT,\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“Question #1:\n",
    "\n",
    "Why is it important to provide a structured response template? (As in: Why are structured outputs helpful/preferred in Agentic workflows?)\n",
    "\n",
    "##### âœ… Answer:\n",
    "Providing a structured response template is important because it ensures that the output from the agent is organized, consistent, and machine-readable. Structured outputs make it easier to parse, validate, and use the agent's responses in downstream processes or automations. In agentic workflows, this helps reduce ambiguity, simplifies integration between components, and ensures that the information returned can be easily consumed by other agents or tools. This leads to more reliable and maintainable systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create Search Agent\n",
    "\n",
    "Now we'll create our Search Agent, which will be responsible for executing web searches based on the terms generated by the Planner Agent. This agent will take each search query, perform a web search using the `WebSearchTool`, and then summarize the results in a concise format.\n",
    "\n",
    "> NOTE: We are using the `WebSearchTool`, a hosted tool that can be used as part of an `OpenAIResponsesModel` as outlined in the [documentation](https://openai.github.io/openai-agents-python/tools/). This is based on the tools available through OpenAI's new [Responses API](https://openai.com/index/new-tools-for-building-agents/).\n",
    "\n",
    "The `SEARCH_PROMPT` below instructs the agent to create brief, focused summaries of search results. These summaries are designed to be 2-3 paragraphs, under 300 words, and capture only the essential information without unnecessary details. The goal is to provide the Writer Agent with clear, distilled information that can be efficiently synthesized into the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PROMPT = (\n",
    "    \"You are a research assistant. Given a search term, you search the web for that term and\"\n",
    "    \"produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300\"\n",
    "    \"words. Capture the main points. Write succinctly, no need to have complete sentences or good\"\n",
    "    \"grammar. This will be consumed by someone synthesizing a report, so its vital you capture the\"\n",
    "    \"essence and ignore any fluff. Do not include any additional commentary other than the summary\"\n",
    "    \"itself.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Search Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `SEARCH_PROMPT` and will utilize the `WebSearchTool` to perform web searches. We're configuring it with `tool_choice=\"required\"` to ensure it always uses the search tool when processing requests.\n",
    "\n",
    "> NOTE: We can, as demonstrated, indicate how we want our model to use tools. You can read more about that at the bottom of the page [here](https://openai.github.io/openai-agents-python/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=SEARCH_PROMPT,\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question #2: \n",
    "\n",
    "What other tools are supported in OpenAI's Responses API?\n",
    "\n",
    "##### âœ… Answer:\n",
    "OpenAI's Responses API currently supports several built-in tools, including web search (WebSearchTool), code interpreter (for running code and working with files), image generation (DALL-E), and data analysis. Additional tools and third-party tool integrations may be available over time as the platform evolves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create Writer Agent\n",
    "\n",
    "Finally, we'll create our Writer Agent, which will synthesize all the research findings into a comprehensive report. This agent takes the original query and the research summaries from the Search Agent, then produces a structured report with follow-up questions.\n",
    "\n",
    "The Writer Agent will:\n",
    "1. Create an outline for the report structure\n",
    "2. Generate a detailed markdown report (5-10 pages)\n",
    "3. Provide follow-up questions for further research\n",
    "\n",
    "We'll define the prompt for this agent in the next cell. This prompt will instruct the Writer Agent on how to synthesize research findings into a comprehensive report with follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research \"\n",
    "    \"assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique questions that would help extend \"\n",
    "    \"this research. Do not repeat questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ—ï¸ Activity #1: \n",
    "\n",
    "This prompt is quite generic - modify this prompt to produce a report that is more personalized to either your personal preference, or more appropriate for a specific use case (eg. law domain research)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will synthesize all the research findings into a comprehensive report. We're configuring it with the `ReportData` output type to structure the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"\"\"A short 2-3 sentence summary of the findings.\"\"\"\n",
    "\n",
    "    markdown_report: str\n",
    "    \"\"\"The final report\"\"\"\n",
    "\n",
    "    follow_up_questions: list[str]\n",
    "    \"\"\"Suggested topics to research further\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will take the original query and research summaries, then synthesize them into a comprehensive report with follow-up questions. We've defined a custom output type called `ReportData` that structures the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=WRITER_PROMPT,\n",
    "    model=\"o3-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question #3: \n",
    "\n",
    "Why are we electing to use a reasoning model for writing our report?\n",
    "\n",
    "##### âœ… Answer:\n",
    "We use a reasoning model for writing our report because such models are optimized for tasks requiring synthesis, critical thinking, and logical organization. When creating a comprehensive report from research findings, the agent must not only summarize information but also connect ideas, draw inferences, and present structured arguments in clear language. Reasoning models are specifically tuned to handle these complex intellectual tasks, leading to higher quality, more coherent, and more insightful reports compared to simpler completion or chat models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create Utility Classes \n",
    "\n",
    "We'll define utility classes to help with displaying progress and managing the research workflow. The Printer class below will provide real-time updates on the research process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Printer class provides real-time progress updates during the research process. It uses Rich's Live display to show dynamic content with spinners for in-progress items and checkmarks for completed tasks. The class maintains a dictionary of items with their completion status and can selectively hide checkmarks for specific items. This creates a clean, interactive console experience that keeps the user informed about the current state of the research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from rich.console import Console, Group\n",
    "from rich.live import Live\n",
    "from rich.spinner import Spinner\n",
    "\n",
    "class Printer:\n",
    "    def __init__(self, console: Console):\n",
    "        self.live = Live(console=console)\n",
    "        self.items: dict[str, tuple[str, bool]] = {}\n",
    "        self.hide_done_ids: set[str] = set()\n",
    "        self.live.start()\n",
    "\n",
    "    def end(self) -> None:\n",
    "        self.live.stop()\n",
    "\n",
    "    def hide_done_checkmark(self, item_id: str) -> None:\n",
    "        self.hide_done_ids.add(item_id)\n",
    "\n",
    "    def update_item(\n",
    "        self, item_id: str, content: str, is_done: bool = False, hide_checkmark: bool = False\n",
    "    ) -> None:\n",
    "        self.items[item_id] = (content, is_done)\n",
    "        if hide_checkmark:\n",
    "            self.hide_done_ids.add(item_id)\n",
    "        self.flush()\n",
    "\n",
    "    def mark_item_done(self, item_id: str) -> None:\n",
    "        self.items[item_id] = (self.items[item_id][0], True)\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        renderables: list[Any] = []\n",
    "        for item_id, (content, is_done) in self.items.items():\n",
    "            if is_done:\n",
    "                prefix = \"âœ… \" if item_id not in self.hide_done_ids else \"\"\n",
    "                renderables.append(prefix + content)\n",
    "            else:\n",
    "                renderables.append(Spinner(\"dots\", text=content))\n",
    "        self.live.update(Group(*renderables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a ResearchManager class that will orchestrate the research process. This class will:\n",
    "1. Plan searches based on the query\n",
    "2. Perform those searches to gather information\n",
    "3. Write a comprehensive report based on the gathered information\n",
    "4. Display progress using our Printer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from agents import Runner, custom_span, gen_trace_id, trace\n",
    "\n",
    "class ResearchManager:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        self.printer = Printer(self.console)\n",
    "\n",
    "    async def run(self, query: str) -> None:\n",
    "        trace_id = gen_trace_id()\n",
    "        with trace(\"Research trace\", trace_id=trace_id):\n",
    "            self.printer.update_item(\n",
    "                \"trace_id\",\n",
    "                f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "\n",
    "            self.printer.update_item(\n",
    "                \"starting\",\n",
    "                \"Starting research...\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "            search_plan = await self._plan_searches(query)\n",
    "            search_results = await self._perform_searches(search_plan)\n",
    "            report = await self._write_report(query, search_results)\n",
    "\n",
    "            final_report = f\"Report summary\\n\\n{report.short_summary}\"\n",
    "            self.printer.update_item(\"final_report\", final_report, is_done=True)\n",
    "\n",
    "            self.printer.end()\n",
    "\n",
    "        print(\"\\n\\n=====REPORT=====\\n\\n\")\n",
    "        print(f\"Report: {report.markdown_report}\")\n",
    "        print(\"\\n\\n=====FOLLOW UP QUESTIONS=====\\n\\n\")\n",
    "        unique_questions = []\n",
    "        seen = set()\n",
    "        \n",
    "        for question in report.follow_up_questions:\n",
    "            if question not in seen:\n",
    "                unique_questions.append(question)\n",
    "                seen.add(question)\n",
    "        \n",
    "        for i, question in enumerate(unique_questions, 1):\n",
    "            print(f\"{i}. {question}\")\n",
    "\n",
    "    async def _plan_searches(self, query: str) -> WebSearchPlan:\n",
    "        self.printer.update_item(\"planning\", \"Planning searches...\")\n",
    "        result = await Runner.run(\n",
    "            planner_agent,\n",
    "            f\"Query: {query}\",\n",
    "        )\n",
    "        self.printer.update_item(\n",
    "            \"planning\",\n",
    "            f\"Will perform {len(result.final_output.searches)} searches\",\n",
    "            is_done=True,\n",
    "        )\n",
    "        return result.final_output_as(WebSearchPlan)\n",
    "\n",
    "    async def _perform_searches(self, search_plan: WebSearchPlan) -> list[str]:\n",
    "        with custom_span(\"Search the web\"):\n",
    "            self.printer.update_item(\"searching\", \"Searching...\")\n",
    "            num_completed = 0\n",
    "            max_concurrent = 5\n",
    "            results = []\n",
    "            \n",
    "            for i in range(0, len(search_plan.searches), max_concurrent):\n",
    "                batch = search_plan.searches[i:i+max_concurrent]\n",
    "                tasks = [asyncio.create_task(self._search(item)) for item in batch]\n",
    "                \n",
    "                for task in asyncio.as_completed(tasks):\n",
    "                    try:\n",
    "                        result = await task\n",
    "                        if result is not None:\n",
    "                            results.append(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Search error: {e}\")\n",
    "                        \n",
    "                    num_completed += 1\n",
    "                    self.printer.update_item(\n",
    "                        \"searching\", f\"Searching... {num_completed}/{len(search_plan.searches)} completed\"\n",
    "                    )\n",
    "            \n",
    "            self.printer.mark_item_done(\"searching\")\n",
    "            return results\n",
    "\n",
    "    async def _search(self, item: WebSearchItem) -> str | None:\n",
    "        input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "        try:\n",
    "            result = await Runner.run(\n",
    "                search_agent,\n",
    "                input,\n",
    "            )\n",
    "            return str(result.final_output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{item.query}': {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _write_report(self, query: str, search_results: list[str]) -> ReportData:\n",
    "        self.printer.update_item(\"writing\", \"Thinking about report...\")\n",
    "        input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "        \n",
    "        result = Runner.run_streamed(\n",
    "            writer_agent,\n",
    "            input,\n",
    "        )\n",
    "        \n",
    "        update_messages = [\n",
    "            \"Thinking about report...\",\n",
    "            \"Planning report structure...\",\n",
    "            \"Writing outline...\",\n",
    "            \"Creating sections...\",\n",
    "            \"Cleaning up formatting...\",\n",
    "            \"Finalizing report...\",\n",
    "            \"Finishing report...\",\n",
    "        ]\n",
    "\n",
    "        last_update = time.time()\n",
    "        next_message = 0\n",
    "        \n",
    "        async for event in result.stream_events():\n",
    "            if time.time() - last_update > 5 and next_message < len(update_messages):\n",
    "                self.printer.update_item(\"writing\", update_messages[next_message])\n",
    "                next_message += 1\n",
    "                last_update = time.time()\n",
    "\n",
    "        self.printer.mark_item_done(\"writing\")\n",
    "        return result.final_output_as(ReportData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ—ï¸ Activity #2:\n",
    "\n",
    "Convert the above flow into a flowchart style image (software of your choosing, but if you're not sure which to use try [Excallidraw](https://excalidraw.com/)) that outlines how the different Agents interact with each other. \n",
    "\n",
    "> HINT: Cursor's AI (CMD+L or CTRL+L on Windows) would be a helpful way to get a basic diagram that you can add more detail to!\n",
    "\n",
    "Answer: activity_2.excalidraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Running Our Agent\n",
    "\n",
    "Now let's run our agent! The main function below will prompt the user for a research topic, then pass that query to our ResearchManager to handle the entire research process. The ResearchManager will: \n",
    "\n",
    "1. Break down the query into search items\n",
    "2. Search for information on each item\n",
    "3. Write a comprehensive report based on the search results\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    query = input(\"What would you like to research? \")\n",
    "    await ResearchManager().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2587225eba44cd390dc579d481ef912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====REPORT=====\n",
      "\n",
      "\n",
      "Report: # Exploring the Multifaceted Term \"MCP\": Definitions and Advantages\n",
      "\n",
      "## Introduction\n",
      "\n",
      "The abbreviation \"MCP\" is a prime example of an acronym whose meaning shifts dramatically based on context. Whether encountered in medicine, technology, engineering, or even everyday language, MCP carries a spectrum of definitions, each accompanied by unique advantages tailored for specific applications. This report aims to comprehensively outline the various interpretations of MCP and to discuss the associated benefits inherent to each domain. By doing so, we seek to provide a cohesive understanding of how one acronym can serve multiple purposes, enhancing performance and functionality in diverse fields.\n",
      "\n",
      "## Overview of MCP Definitions\n",
      "\n",
      "Given its widespread usage, the term \"MCP\" can be encountered in multiple disciplines. Here, we classify and briefly describe some of the most prominent interpretations:\n",
      "\n",
      "### 1. Medical Interpretations\n",
      "\n",
      "- **Metacarpophalangeal Joint (MCP Joint):** This refers to the joints located between the metacarpal bones of the hand and the proximal phalanges of the fingers, commonly known as knuckles. These joints are crucial for dexterous movement, enabling flexion, extension, abduction, adduction, and rotational movements. \n",
      "\n",
      "- **Membrane Cofactor Protein (CD46):** A type I transmembrane protein involved in regulating the complement system, this protein serves as a protective agent for host cells against complement-mediated attacks. \n",
      "\n",
      "- **Modified Citrus Pectin (MCP):** Derived from the soluble fiber of citrus peels, modified citrus pectin has garnered interest for its potential benefits in cancer support, cardiovascular health, and detoxification processes.\n",
      "\n",
      "- **Monocyte Chemoattractant Protein:** This family of chemokines plays a key role in directing the movement of monocytes towards inflammation sites, thus being a critical component of the immune response.\n",
      "\n",
      "### 2. Technology and Computing\n",
      "\n",
      "- **Model Context Protocol (MCP):** Introduced by Anthropic in November 2024, this open standard facilitates seamless integration of artificial intelligence systems, particularly large language models, with external tools, data sources, and APIs. It offers a standardized, dynamic, and bidirectional communication framework that improves AI functionalities.\n",
      "\n",
      "- **Multi-Core Processor (MCP):** In computing, this refers to a processor design that houses two or more independent cores on a single chip, enhancing multitasking, parallel processing, and overall performance for modern computing needs.\n",
      "\n",
      "- **Microsoft Certified Professional (MCP):** A certification for individuals who have demonstrated expertise in Microsoft technologies, underlining a commitment to proficiency in IT domains.\n",
      "\n",
      "- **Other Computing Interpretations:** Additional definitions in technology include Master Control Program (historical operating system) and even file types or programming projects, each contributing uniquely to the field of software development.\n",
      "\n",
      "### 3. Engineering and Electronics\n",
      "\n",
      "- **Mode Control Panel (MCP):** Widely used in advanced aviation, the MCP is an instrument panel that allows pilots to control an aircraftâ€™s autopilot systems, ensuring safe navigation through automated adjustments.\n",
      "\n",
      "- **Microchannel Plate Detector (MCP):** Known for its high sensitivity, fast response, and compact form factor, this device detects single particles or photons, finding applications in imaging and scientific instrumentation.\n",
      "\n",
      "- **Multi-Chip Packaging (MCP):** This technique involves integrating multiple semiconductor chips within a single package. The advantages include improved performance through shortened electrical paths, enhanced signal integrity, space efficiency, and lower production costs.\n",
      "\n",
      "- **Additional Engineering Applications:** In areas like modular central plants for utilities or mixed complementarity problems in operations research, MCP shows how efficiency, cost-effectiveness, and optimization are integral to modern engineering solutions.\n",
      "\n",
      "### 4. Other Contexts and Divergent Meanings\n",
      "\n",
      "Outside of the technical and scientific realms, the acronym MCP has broader social and practical meanings:\n",
      "\n",
      "- **Male Chauvinist Pig:** A derogatory term used in sociological contexts to describe sexist attitudes in men.\n",
      "\n",
      "- **Political and Law Enforcement References:** Examples include the Malawi Congress Party in politics and the Montgomery County Police Department in law enforcement.\n",
      "\n",
      "- **Educational and Commercial Usage:** Other interpretations include initiatives like educational programs and various business or service certifications such as the Microsoft Certified Partner designation.\n",
      "\n",
      "## Advantages of MCP in Various Contexts\n",
      "\n",
      "The multiplicity of MCPâ€™s definitions inherently means that the advantages vary widely based on the application. This section organizes these advantages by their corresponding context to highlight the transformative impact of each interpretation:\n",
      "\n",
      "### A. Medical Advantages\n",
      "\n",
      "1. **Enhanced Joint Functionality:** In the case of the metacarpophalangeal joint, MCP provides a wide range of motion, essential for everyday activities that require fine motor skills such as gripping and manipulating objects.\n",
      "\n",
      "2. **Regulatory Role in Immune Response:** The membrane cofactor protein (CD46) offers robust protection against inappropriate complement activation, thus safeguarding tissues from immune-mediated injuries.\n",
      "\n",
      "3. **Therapeutic Benefits of Modified Citrus Pectin:** MCP has been investigated for its potential roles in inhibiting cancer cell metastasis, reducing cardiovascular inflammation, and aiding in detoxification by binding heavy metals, thereby potentially improving patient outcomes.\n",
      "\n",
      "4. **Immune System Regulation:** Monocyte chemoattractant proteins support the body's immunological response by guiding immune cells to sites of infection or injury, which is critical in managing inflammatory processes.\n",
      "\n",
      "### B. Technological and AI Integration Advantages\n",
      "\n",
      "1. **Standardized Communication in AI Systems:** The Model Context Protocol (MCP) standardizes the way AI models interact with external tools. This reduces development complexity by providing a universal interface, which eases the integration of disparate systems and data sources.\n",
      "\n",
      "2. **Dynamic and Bidirectional Data Exchange:** Unlike traditional APIs with fixed endpoints, MCP allows for stateful, real-time interactions that ensure continuous contextual awareness between AI agents and the services they utilize.\n",
      "\n",
      "3. **Scalability and Future-Proofing:** With its modular design, MCP's architecture enables simple additions of new capabilities without necessitating disruptive changes to the existing system. This makes it particularly attractive for long-term AI deployments.\n",
      "\n",
      "4. **Enhanced Security Features:** Integration standards such as MCP embed enterprise-level security, including fine-grained permission management and robust authentication, which are key to protecting sensitive data and ensuring compliance with regulatory requirements.\n",
      "\n",
      "### C. Electronics and Engineering Advantages\n",
      "\n",
      "1. **Multi-Chip Packaging (MCP) in Electronics:** This approach offers several compelling benefits:\n",
      "   - **Performance Enhancement:** By reducing the distance signals must travel between components, MCP helps improve operational speeds and reduces latency.\n",
      "   - **Space Efficiency:** The vertical stacking of chips conserves precious real estate on printed circuit boards, which is essential in compact devices like smartphones and wearable technology.\n",
      "   - **Cost Efficiency and Reliability:** Consolidation reduces manufacturing complexity and enhances assembly yields, resulting in lower production costs and improved reliability of electronic products.\n",
      "\n",
      "2. **Innovations in Instrumentation:** Devices such as microchannel plate detectors enable extremely sensitive detection of light and particles, which is critical for applications ranging from medical imaging to astrophysics.\n",
      "\n",
      "3. **Aviation and Control Systems:** The Mode Control Panel in aircraft not only facilitates automation of flight systems but also enhances safety by providing pilots with precise control over autopilot functions and flight parameters.\n",
      "\n",
      "### D. Broader Societal and Practical Advantages\n",
      "\n",
      "- **Professional Certification and Skill Validation:** In the realm of IT, the designation of Microsoft Certified Professional (MCP) assists in career advancement by certifying individualsâ€™ expertise in Microsoft technologies, thus ensuring a high level of competency in industry practices.\n",
      "\n",
      "- **Streamlined Process and Reduced Complexity:** Whether in contractual management through minimum contract periods or standardization in communication protocols in networking, MCP helps simplify and streamline processes across various administrative and operational domains.\n",
      "\n",
      "## Analysis and Discussion\n",
      "\n",
      "The varied advantages of MCP across disciplines underscore the importance of context when considering both the interpretation and benefits of the term. In many cases, the advantages are directly tied to the functionality they enhance:\n",
      "\n",
      "- In healthcare, where precision and safety are paramount, MCP contributes to either the physical functionality of joints or the regulatory control in biological systems.\n",
      "- In technology and AI, the Model Context Protocol stands as a critical enabler for dynamic, secure, and future-proofed integrations between digital systems and AI agents. Its ability to offer real-time, context-sensitive communication is a game-changer in how artificial intelligence systems are implemented.\n",
      "- In electronics and engineering, enhancements in performance, cost reductions, and design flexibility are significant, particularly given the ongoing drive towards miniaturization and increased computational efficiency.\n",
      "\n",
      "Despite its advantages, the adoption of certain MCP standardsâ€”such as the Model Context Protocolâ€”comes with challenges. These include potential security vulnerabilities, scalability concerns in high-context environments, and operational complexity during deployment and integration. However, these challenges are often outweighed by the transformative benefits, especially in sectors where integration and performance are key to success.\n",
      "\n",
      "## Conclusion and Future Research Directions\n",
      "\n",
      "In summary, MCP is not a monolithic concept but an umbrella term with diverse meanings across multiple fields. Its advantages vary accordingly: from enhancing human joint mobility and immune regulation in medicine to bolstering AI integration with secure, dynamic protocols in technology, and ultimately improving performance and efficiency in electronics and engineering applications. This multiplicity of meanings emphasizes the need for clear, context-specific usage when discussing MCP.\n",
      "\n",
      "As research continues to evolve in these domains, it will be beneficial to explore further how MCP-based systems can be optimized, how emerging security challenges are addressed, and which novel applications might emerge through interdisciplinary collaboration. The ability to harness the full potential of MCP, especially in rapidly advancing fields like AI and personalized medicine, promises to revolutionize multiple industries.\n",
      "\n",
      "---\n",
      "\n",
      "## Follow-Up Questions\n",
      "\n",
      "1. How can the Model Context Protocol be further enhanced to mitigate its current security vulnerabilities while maintaining dynamic integration capabilities?\n",
      "2. In what ways can modified citrus pectin be optimized for use in clinical settings to maximize its therapeutic benefits?\n",
      "3. Are there opportunities to integrate AI-driven MCP systems in personalized healthcare, and what challenges might arise?\n",
      "4. How might advances in multi-chip packaging influence the design and performance of next-generation mobile devices?\n",
      "5. What role does context play in determining the success of MCP implementations across different industries, and how can cross-disciplinary lessons be applied?\n",
      "\n",
      "\n",
      "\n",
      "=====FOLLOW UP QUESTIONS=====\n",
      "\n",
      "\n",
      "1. How can the Model Context Protocol be further enhanced to mitigate its current security vulnerabilities while maintaining dynamic integration capabilities?\n",
      "2. In what ways can modified citrus pectin be optimized for use in clinical settings to maximize its therapeutic benefits?\n",
      "3. Are there opportunities to integrate AI-driven MCP systems in personalized healthcare, and what challenges might arise?\n",
      "4. How might advances in multi-chip packaging influence the design and performance of next-generation mobile devices?\n",
      "5. What role does context play in determining the success of MCP implementations across different industries, and how can cross-disciplinary lessons be applied?\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sample Report in Markdown \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agents SDK: A Comprehensive Report\n",
    "\n",
    "*Published: October 2023*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Core Concepts and Key Features](#core-concepts-and-key-features)\n",
    "3. [Architecture and Developer Experience](#architecture-and-developer-experience)\n",
    "4. [Comparative Analysis with Alternative Frameworks](#comparative-analysis-with-alternative-frameworks)\n",
    "5. [Integrations and Real-World Applications](#integrations-and-real-world-applications)\n",
    "6. [Troubleshooting, Observability, and Debugging](#troubleshooting-observability-and-debugging)\n",
    "7. [Community Impact and Future Directions](#community-impact-and-future-directions)\n",
    "8. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In March 2025, OpenAI released the Agents SDK, a groundbreaking, open-source framework aimed at simplifying the development of autonomous AI agents capable of performing intricate tasks with minimal human intervention. Designed with a Python-first approach, the SDK offers a minimal set of abstractions, yet provides all the necessary components to build, debug, and optimize multi-agent workflows. The release marked a significant milestone for developers who seek to integrate large language models (LLMs) with advanced task delegation mechanisms, enabling next-generation automation in various industries.\n",
    "\n",
    "The primary goal of the OpenAI Agents SDK is to streamline the creation of agentic applications by offering core primitives such as *agents*, *handoffs*, and *guardrails*. These primitives are essential for orchestrating autonomous AI systems that perform key functions such as web search, file operations, and even actions on a computer. This report delves into the SDK's features, its operational architecture, integration capabilities, and how it compares to other frameworks in the rapidly evolving landscape of AI development tools.\n",
    "\n",
    "## Core Concepts and Key Features\n",
    "\n",
    "### Agents\n",
    "\n",
    "At the heart of the SDK are **agents**â€”intelligent entities that encapsulate a specific set of instructions and tools. Each agent is built on top of a large language model and can be customized with its own personality, domain expertise, and operational directives. For example, a \"Math Tutor\" agent could be designed to solve math problems by explaining each step clearly.\n",
    "\n",
    "**Key elements of an agent include:**\n",
    "\n",
    "- **Instructions:** Specific guidelines that shape the agent's responses and behavior in the context of its designated role.\n",
    "- **Tools:** Predefined or dynamically integrated tools that the agent can leverage to access external resources (e.g., web search or file search functionalities).\n",
    "\n",
    "### Handoffs\n",
    "\n",
    "A unique feature introduced by the SDK is the concept of **handoffs**. Handoffs allow agents to delegate tasks to one another based on expertise and contextual needs. This orchestration paves the way for sophisticated workflows where multiple agents work in tandem, each contributing its specialized capabilities to complete a complex task.\n",
    "\n",
    "### Guardrails\n",
    "\n",
    "Safety and reliability remain a cornerstone in AI development, and the SDK introduces **guardrails** as a means of controlling input and output validation. Guardrails help ensure that agents operate within defined safety parameters, preventing unintended actions and mitigating risks associated with autonomous decision-making.\n",
    "\n",
    "### Built-in Debugging and Observability\n",
    "\n",
    "The development process is further enhanced by built-in **tracing and visualization tools**. These tools offer real-time insights into agent interactions, tool invocations, and decision-making pathways, thereby making debugging and optimization more accessible and systematic. The tracing functionality is a vital feature for developers looking to fine-tune agent performance in production environments.\n",
    "\n",
    "## Architecture and Developer Experience\n",
    "\n",
    "### Python-First Approach\n",
    "\n",
    "The SDK is inherently Python-based, making it highly accessible to the vast community of Python developers. By leveraging existing language features without introducing excessive abstractions, the SDK provides both simplicity and power. The installation is straightforward:\n",
    "\n",
    "```bash\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install openai-agents\n",
    "```\n",
    "\n",
    "Once installed, developers can create and configure agents with minimal boilerplate code. The emphasis on a minimal learning curve has been a significant point of praise among early adopters.\n",
    "\n",
    "### Developer Tools and Tutorials\n",
    "\n",
    "In addition to comprehensive official documentation available on OpenAIâ€™s GitHub pages, the community has contributed numerous tutorials and code examples. Video tutorials by experts such as Sam Witteveen and James Briggs provide hands-on demonstrations, ranging from simple agent creation to more sophisticated scenarios involving parallel execution and advanced tool integrations.\n",
    "\n",
    "### Use of Python's Ecosystem\n",
    "\n",
    "The integration with Pythonâ€™s ecosystem means that developers can immediately apply a range of established libraries and frameworks. For instance, utilizing Pydantic for input validation in guardrails or leveraging visualization libraries to display agent workflows are examples of how the SDK embraces the strengths of Python.\n",
    "\n",
    "## Comparative Analysis with Alternative Frameworks\n",
    "\n",
    "While the OpenAI Agents SDK has received acclaim for its simplicity and robust integration with OpenAIâ€™s ecosystem, other frameworks such as LangGraph, CrewAI, and AutoGen have emerged as viable alternatives. Hereâ€™s how they compare:\n",
    "\n",
    "- **LangGraph:** Known for its graph-based architecture, LangGraph is ideal for handling complex and cyclical workflows that require sophisticated state management. However, it comes with a steeper learning curve, making it less accessible for projects that require quick prototyping.\n",
    "\n",
    "- **CrewAI:** Emphasizing a role-based multi-agent system, CrewAI excels in scenarios where collaboration among agents is critical. Its design promotes clear segregation of duties among different agents, which can be beneficial in customer service or large-scale business automation.\n",
    "\n",
    "- **AutoGen:** This framework supports flexible conversation patterns and diverse agent interactions, particularly useful in applications where adaptive dialogue is essential. Nevertheless, AutoGen may introduce additional overhead when managing state and coordinating multiple agents.\n",
    "\n",
    "In contrast, the OpenAI Agents SDK strikes an effective balance by offering a lightweight yet powerful toolset geared towards production readiness. Its strengths lie in its minimal abstractions, ease of integration with various tools (like web search and file search), and built-in observability features that are crucial for debugging and tracing agent interactions.\n",
    "\n",
    "## Integrations and Real-World Applications\n",
    "\n",
    "### Diverse Integrations\n",
    "\n",
    "The real power of the OpenAI Agents SDK surfaces when it is integrated with other systems and platforms. Notable integrations include:\n",
    "\n",
    "- **Box Integration:** Enhancing enterprise content management, Box has adopted the SDK to enable secure AI-powered data processing. This integration allows agents to reliably access and interpret proprietary data.\n",
    "\n",
    "- **Coinbase AgentKit:** With financial capabilities in mind, Coinbase introduced AgentKit, leveraging the SDK to incorporate financial operations and risk analysis directly into AI agents.\n",
    "\n",
    "- **Milvus and Ollama:** These integrations allow the SDK to handle high-performance data queries and run agents on local infrastructure respectively, ensuring both speed and privacy.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "The versatility of the SDK lends itself to a multitude of applications:\n",
    "\n",
    "- **Customer Support:** Automated agents can be built to handle customer inquiries, providing faster and more accurate responses while reducing workload on human agents.\n",
    "\n",
    "- **Content Generation:** In marketing and media, agents can generate high-quality articles, detailed reports, and even code reviews with built-in content guidelines.\n",
    "\n",
    "- **Financial Analysis:** Specialized agents capable of real-time data fetching and market analysis can generate actionable insights for investors and analysts.\n",
    "\n",
    "- **Health and Wellness:** Custom agents can handle tasks such as appointment scheduling, patient record management, and even provide personalized fitness and dietary recommendations.\n",
    "\n",
    "- **Educational Tools:** Intelligent tutoring agents can assist students by providing personalized learning experiences and instant feedback on assignments.\n",
    "\n",
    "These applications underscore the SDKâ€™s transformative potential across various industries, driving the trend towards increased automation and efficiency.\n",
    "\n",
    "## Troubleshooting, Observability, and Debugging\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "As with any cutting-edge technology, developers working with the OpenAI Agents SDK have encountered challenges:\n",
    "\n",
    "- **API Key Management:** Authentication errors due to missing or invalid API keys are common. The solution involves ensuring that the `OPENAI_API_KEY` environment variable is correctly set or programmatically configured using OpenAIâ€™s helper functions.\n",
    "\n",
    "- **Rate Limitations:** Rate limits, an intrinsic challenge with API-based services, require developers to monitor dashboard usage and implement retry strategies with exponential backoff.\n",
    "\n",
    "- **Response Delays:** Network latency and high server loads can result in unexpected delays. Developers are advised to check network settings, adhere to best practices in setting request timeouts, and monitor OpenAIâ€™s service status.\n",
    "\n",
    "### Built-In Tracing Capabilities\n",
    "\n",
    "The SDK provides robust tracing tools that log agent inputs, outputs, tool interactions, and error messages. This level of observability is crucial for debugging complex workflows and allows developers to visualize the agentâ€™s decision-making process in real time. By configuring a `TracingConfig` object, developers can capture detailed insights and identify performance bottlenecks.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Prompt Engineering:** Refine prompts to reduce ambiguity and minimize unexpected outputs.\n",
    "- **Layered Validation:** Use guardrails extensively to ensure inputs and outputs are verified at multiple layers.\n",
    "- **Modular Design:** Break complex tasks into smaller, more manageable components using handoffs to delegate tasks appropriately.\n",
    "\n",
    "## Community Impact and Future Directions\n",
    "\n",
    "### Developer and Enterprise Adoption\n",
    "\n",
    "The release of the OpenAI Agents SDK has been met with enthusiasm within the developer community. Its ease of use, combined with comprehensive documentation and community-driven resources (such as tutorials on Class Central and DataCamp), has accelerated its adoption across educational, enterprise, and research sectors.\n",
    "\n",
    "Several leading organizations, including Box and Coinbase, have integrated the SDK into their workflows, demonstrating its capability to drive real-world business solutions. The open-source nature of the SDK, licensed under the MIT License, further encourages widespread industrial collaboration and innovation.\n",
    "\n",
    "### Future Prospects\n",
    "\n",
    "Looking forward, OpenAI plans to extend the SDKâ€™s support beyond Python, potentially embracing other programming languages like JavaScript. Additionally, future updates are anticipated to expand tool integrations, further enhance safety mechanisms, and streamline the development of multi-agent ecosystems. Planned deprecations of older APIs, such as the Assistants API in favor of the more unified Responses API, underline the SDKâ€™s evolving roadmap aimed at future-proofing agentic applications.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The OpenAI Agents SDK represents a significant step forward in the field of AI development. Its lightweight, Python-first framework facilitates the creation of autonomous agents that can handle a wide array of tasksâ€”from simple inquiries to complex multi-agent systems. The SDKâ€™s robust integration capabilities, combined with its focus on safety and observability, make it an ideal choice for both developers and enterprises seeking to build reliable, scalable agentic applications.\n",
    "\n",
    "In summary, the SDK not only lowers the barrier to entry for developing sophisticated AI applications but also sets the stage for further innovations as the ecosystem evolves. It is poised to become a standard toolkit for the next generation of AI-driven technologies, empowering users across sectors to achieve greater efficiency and creativity in task automation.\n",
    "\n",
    "---\n",
    "\n",
    "*For further reading, developers are encouraged to visit the official OpenAI documentation, join the community forums, and explore real-world use cases to deepen their understanding of this transformative tool.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
